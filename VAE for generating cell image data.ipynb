{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from https://olaralex.com/variational-auto-encoder-with-cifar-10-2/\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow.compat.v1 as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('./Datasets/cells_64x64_it_50.pkl')\n",
    "X = np.stack(data['features'].to_numpy(),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of minibatches:  15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ymirkhang/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/client/session.py:1750: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 23s 2s/step - cost: 57677761.8667\n",
      "15/15 [==============================] - 23s 2s/step - cost: 24424347.8000\n",
      "15/15 [==============================] - 41s 3s/step - cost: 17537729.1333\n",
      " 3/15 [=====>........................] - ETA: 41s - cost: 16095729.6667"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convolutional structure for the encoder net\n",
    "\n",
    "encoder = tf.keras.Sequential([\n",
    "    layers.Conv2D(filters=64 , kernel_size=4, strides=2, activation=tf.nn.relu, padding='same'),\n",
    "    layers.Conv2D(filters=128, kernel_size=4, strides=2, activation=tf.nn.relu, padding='same'),\n",
    "    layers.Conv2D(filters=512, kernel_size=4, strides=2, activation=tf.nn.relu, padding='same'),\n",
    "    layers.Flatten()\n",
    "])\n",
    "\n",
    "# DeConv structure for the decoder net\n",
    "\n",
    "decoder = tf.keras.Sequential([\n",
    "    layers.Dense(2048),\n",
    "    layers.Reshape(target_shape=(4, 4, 128), input_shape=(None, 1024)),\n",
    "    layers.Conv2DTranspose(filters=256, kernel_size=4, strides=2, activation=tf.nn.relu, padding='same'),\n",
    "    layers.Conv2DTranspose(filters=64 , kernel_size=4, strides=2, activation=tf.nn.relu, padding='same'),\n",
    "    layers.Conv2DTranspose(filters=3  , kernel_size=4, strides=2, activation=tf.nn.relu, padding='same')\n",
    "])\n",
    "\n",
    "batch_size = 250\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[batch_size, 32, 32, 3])\n",
    "\n",
    "encoded = encoder(x)\n",
    "\n",
    "mean = layers.Dense(1024, tf.nn.softplus)(encoded)\n",
    "sigma = layers.Dense(1024, tf.nn.relu)(encoded)\n",
    "\n",
    "z = mean + tf.multiply(tf.sqrt(tf.exp(sigma)),\n",
    "                       tf.random_normal(shape=(batch_size, 1024)))\n",
    "\n",
    "x_reco = decoder(z)\n",
    "\n",
    "reconstruction_term = -tf.reduce_sum(tfp.distributions.MultivariateNormalDiag(\n",
    "    layers.Flatten()(x_reco), scale_identity_multiplier=0.05).log_prob(layers.Flatten()(x)))\n",
    "\n",
    "kl_divergence = tf.reduce_sum(tf.keras.metrics.kullback_leibler_divergence(x, x_reco), axis=[1, 2])\n",
    "\n",
    "cost = tf.reduce_mean(reconstruction_term + kl_divergence)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(cost)\n",
    "\n",
    "runs = 20\n",
    "n_minibatches = int(X.shape[0] / batch_size)\n",
    "\n",
    "print(\"Number of minibatches: \", n_minibatches)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for epoch in range(runs):\n",
    "    pbar = tf.keras.utils.Progbar(n_minibatches)\n",
    "    for i in range(n_minibatches):\n",
    "        \n",
    "        x_batch = X[i*batch_size:(i+1)*batch_size,:32,:32]\n",
    "        cost_, _ = sess.run((cost, optimizer), feed_dict={x: x_batch})\n",
    "\n",
    "        pbar.add(1,[(\"cost\",cost_)])\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             multiple                  2099200   \n",
      "_________________________________________________________________\n",
      "reshape_11 (Reshape)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_33 (Conv2DT multiple                  524544    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_34 (Conv2DT multiple                  262208    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_35 (Conv2DT multiple                  3075      \n",
      "=================================================================\n",
      "Total params: 2,889,027\n",
      "Trainable params: 2,889,027\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "# display results\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "n_rec = 10\n",
    "\n",
    "x_batch = X_train[0:batch_size]\n",
    "\n",
    "plt.figure(figsize=(n_rec+6,4))\n",
    "\n",
    "pred_img = sess.run(x_reco, feed_dict={x: x_batch})\n",
    "pred_img = pred_img.reshape(batch_size, 32, 32, 3)\n",
    "pred_img = pred_img.astype(np.int32)\n",
    "\n",
    "for i in range(n_rec):\n",
    "    \n",
    "    plt.subplot(2, n_rec, i+1)\n",
    "    plt.imshow(x_batch[i])\n",
    "\n",
    "    plt.subplot(2, n_rec, n_rec+i+1)\n",
    "    plt.imshow(pred_img[i])\n",
    "\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
