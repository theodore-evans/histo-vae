{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/theoevans/anaconda3/envs/cv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/theoevans/anaconda3/envs/cv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/theoevans/anaconda3/envs/cv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/theoevans/anaconda3/envs/cv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/theoevans/anaconda3/envs/cv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/theoevans/anaconda3/envs/cv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/theoevans/anaconda3/envs/cv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/theoevans/anaconda3/envs/cv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/theoevans/anaconda3/envs/cv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/theoevans/anaconda3/envs/cv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/theoevans/anaconda3/envs/cv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/theoevans/anaconda3/envs/cv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "from Models.Augment import Augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.9254902  0.9254902  0.93333334]\n",
      "   [0.9254902  0.9254902  0.93333334]\n",
      "   [0.92941177 0.92941177 0.92941177]\n",
      "   ...\n",
      "   [0.9019608  0.8784314  0.9254902 ]\n",
      "   [0.9411765  0.91764706 0.95686275]\n",
      "   [0.94509804 0.92156863 0.9607843 ]]\n",
      "\n",
      "  [[0.9372549  0.91764706 0.90588236]\n",
      "   [0.94509804 0.9254902  0.9137255 ]\n",
      "   [0.9490196  0.93333334 0.92156863]\n",
      "   ...\n",
      "   [0.88235295 0.8666667  0.92156863]\n",
      "   [0.93333334 0.92156863 0.9647059 ]\n",
      "   [0.9411765  0.92941177 0.95686275]]\n",
      "\n",
      "  [[0.95686275 0.9137255  0.8901961 ]\n",
      "   [0.9647059  0.92941177 0.9019608 ]\n",
      "   [0.972549   0.94509804 0.92156863]\n",
      "   ...\n",
      "   [0.8666667  0.85882354 0.9137255 ]\n",
      "   [0.92156863 0.91764706 0.9490196 ]\n",
      "   [0.9411765  0.9372549  0.95686275]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.92941177 0.9137255  0.96862745]\n",
      "   [0.9137255  0.9019608  0.94509804]\n",
      "   [0.9098039  0.90588236 0.9372549 ]\n",
      "   ...\n",
      "   [0.77254903 0.627451   0.5254902 ]\n",
      "   [0.8627451  0.72156864 0.63529414]\n",
      "   [0.9647059  0.84313726 0.77254903]]\n",
      "\n",
      "  [[0.87058824 0.8627451  0.9137255 ]\n",
      "   [0.8627451  0.85490197 0.90588236]\n",
      "   [0.8745098  0.8745098  0.90588236]\n",
      "   ...\n",
      "   [0.84705883 0.7411765  0.65882355]\n",
      "   [0.8901961  0.7882353  0.7294118 ]\n",
      "   [0.972549   0.8862745  0.8352941 ]]\n",
      "\n",
      "  [[0.8039216  0.8        0.85490197]\n",
      "   [0.8039216  0.8117647  0.8627451 ]\n",
      "   [0.83137256 0.84313726 0.8784314 ]\n",
      "   ...\n",
      "   [0.85882354 0.7882353  0.73333335]\n",
      "   [0.8666667  0.8        0.7607843 ]\n",
      "   [0.9372549  0.88235295 0.84705883]]]\n",
      "\n",
      "\n",
      " [[[0.85882354 0.87058824 0.92941177]\n",
      "   [0.89411765 0.9019608  0.9529412 ]\n",
      "   [0.9098039  0.9098039  0.95686275]\n",
      "   ...\n",
      "   [0.9411765  0.9411765  0.9490196 ]\n",
      "   [0.9372549  0.9372549  0.94509804]\n",
      "   [0.92941177 0.92941177 0.9372549 ]]\n",
      "\n",
      "  [[0.8392157  0.84705883 0.8980392 ]\n",
      "   [0.9019608  0.9019608  0.9490196 ]\n",
      "   [0.9372549  0.92941177 0.972549  ]\n",
      "   ...\n",
      "   [0.9411765  0.9411765  0.9490196 ]\n",
      "   [0.92941177 0.92941177 0.9372549 ]\n",
      "   [0.91764706 0.91764706 0.9254902 ]]\n",
      "\n",
      "  [[0.84705883 0.84705883 0.8862745 ]\n",
      "   [0.9137255  0.9098039  0.9411765 ]\n",
      "   [0.9411765  0.92941177 0.95686275]\n",
      "   ...\n",
      "   [0.9647059  0.9647059  0.972549  ]\n",
      "   [0.9607843  0.9607843  0.96862745]\n",
      "   [0.9372549  0.9372549  0.94509804]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.93333334 0.92941177 0.92156863]\n",
      "   [0.9137255  0.90588236 0.9098039 ]\n",
      "   [0.8980392  0.8980392  0.90588236]\n",
      "   ...\n",
      "   [0.6627451  0.49803922 0.43529412]\n",
      "   [0.7254902  0.57254905 0.5058824 ]\n",
      "   [0.75686276 0.6117647  0.54901963]]\n",
      "\n",
      "  [[0.9254902  0.9098039  0.8980392 ]\n",
      "   [0.8862745  0.88235295 0.8745098 ]\n",
      "   [0.85882354 0.8509804  0.85490197]\n",
      "   ...\n",
      "   [0.7019608  0.52156866 0.45882353]\n",
      "   [0.7019608  0.53333336 0.46666667]\n",
      "   [0.6862745  0.53333336 0.46666667]]\n",
      "\n",
      "  [[0.8117647  0.84313726 0.93333334]\n",
      "   [0.7607843  0.8        0.8980392 ]\n",
      "   [0.7490196  0.8039216  0.90588236]\n",
      "   ...\n",
      "   [0.76862746 0.5529412  0.43529412]\n",
      "   [0.7647059  0.5647059  0.45882353]\n",
      "   [0.7529412  0.57254905 0.47843137]]]]\n"
     ]
    }
   ],
   "source": [
    "THIS_DIR = os.path.abspath('')\n",
    "DATASETS_DIR = \"Datasets/\"\n",
    "dataset_npz = \"cells_64x64_it_50.npz\"\n",
    "\n",
    "dataset_npz_filepath = os.path.join(THIS_DIR, DATASETS_DIR, dataset_csv)\n",
    "data = np.load(dataset_npz_filepath, allow_pickle = True)\n",
    "    \n",
    "features = data[\"features\"]\n",
    "target = data[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size = 0.33, random_state=42)\n",
    "print(np.append(X_test[0], features[0], axis= 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without augmentation:\n",
      "(2542,) (2542,) (1253,) (1253,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 3 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-67ea3444a136>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_train_and_test_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_npz_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-67ea3444a136>\u001b[0m in \u001b[0;36mcreate_train_and_test_files\u001b[0;34m(npz_filepath, test_size, augment, transformations)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtransformed_image\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransformed_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                 \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mappend\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(arr, values, axis)\u001b[0m\n\u001b[1;32m   4691\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4692\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4693\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 3 dimension(s)"
     ]
    }
   ],
   "source": [
    "def create_train_and_test_files(npz_filepath, test_size = 0.33, augment = True, transformations = ['rotate', 'flip']):\n",
    "    \n",
    "    data = np.load(npz_filepath, allow_pickle = True)\n",
    "    \n",
    "    features = data[\"features\"]\n",
    "    target = data[\"target\"]\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size = test_size, random_state=42)\n",
    "    \n",
    "    print(\"Without augmentation:\")\n",
    "    print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "    \n",
    "    if augment:\n",
    "        aug = Augment()\n",
    "        for i in range(0, len(X_train)):\n",
    "            image_to_transform = X_train[i]\n",
    "            target = y_train[i]\n",
    "            transformed_images = aug.TransformImage(image_to_transform, transformations)\n",
    "            \n",
    "            for transformed_image in transformed_images:\n",
    "                X_train = np.append(X_train, transformed_image, axis = 0)\n",
    "                y_train = np.append(y_train, target, axis = 0)\n",
    "\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        \n",
    "        print(\"With augmentation:\")\n",
    "        print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "        \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = create_train_and_test_files(dataset_npz_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2542,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset_name):\n",
    "    this_dir = os.path.abspath('')\n",
    "    datasets_dir = os.path.join(this_dir, DATASETS_DIR)\n",
    "\n",
    "    return np.load(f\"{datasets_dir}{dataset_name}.npz\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['non_tumor', 'non_tumor', 'non_tumor', ..., 'tumor', 'non_tumor',\n",
       "       'tumor'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['y_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tf_training_files(dataset_name, batch_size = 512, shuffle = True):\n",
    "\n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"x\": train_test_data['X_train']},\n",
    "        y=train_test_data['y_train'],\n",
    "        num_epochs=None,\n",
    "        shuffle=True)\n",
    "        \n",
    "estimator = generate_tf_training_files(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CV)",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
